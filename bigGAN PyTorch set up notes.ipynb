{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/huggingface/pytorch-pretrained-BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pytorch-pretrained-biggan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prob full requirements ultimately necessary; \"If you want to use the conversion scripts and the imagenet utilities, additional requirements are needed, in particular TensorFlow and NLTK. To install all the requirements please use the full_requirements.txt file\". See source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git\n",
    "!cd pytorch-pretrained-BigGAN\n",
    "#!pip install -r full_requirements.txt # <- doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of above installation, content full_requirements.txt copied and installed:\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-hub\n",
    "!pip install Pillow\n",
    "!pip install nltk\n",
    "!pip install libsixel-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install libsixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used in terminal to install libsixel:\n",
    "# $ git clone https://github.com/saitoha/libsixel.git\n",
    "# $ cd libsixel\n",
    "# $ ./configure --enable-python --prefix=/usr/local\n",
    "# $ make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if libsixel finally working:\n",
    "from libsixel import sixel_output_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below all directly copied from https://github.com/huggingface/pytorch-pretrained-BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an input\n",
    "# truncation was 0.4\n",
    "truncation = 0.4\n",
    "class_vector = (one_hot_from_names(['soap bubble'], batch_size=1) + one_hot_from_names(['coffee'], batch_size=1))/2\n",
    "#class_vector = one_hot_from_names(['volcano'], batch_size=1)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1)\n",
    "\n",
    "# All in tensors\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "# noise_vector = noise_vector.to('cuda')\n",
    "# class_vector = class_vector.to('cuda')\n",
    "# model.to('cuda')\n",
    "\n",
    "# Generate an image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# If you have a GPU put back on CPU\n",
    "# output = output.to('cpu')\n",
    "\n",
    "# If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "# (see https://github.com/saitoha/libsixel for details)\n",
    "#display_in_terminal(output)\n",
    "\n",
    "# Save results as png images\n",
    "save_as_images(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
