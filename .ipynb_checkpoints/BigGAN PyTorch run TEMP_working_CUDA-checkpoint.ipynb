{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16964,
     "status": "ok",
     "timestamp": 1570613343964,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "svvzrzwY39EF",
    "outputId": "29449da8-8f39-45da-e2d7-d31a5e522e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0rc3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 3.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
      "\u001b[31mERROR: tensorflow-gpu 1.12.2 has requirement tensorboard<1.13.0,>=1.12.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard\n",
      "  Found existing installation: tensorboard 1.12.2\n",
      "    Uninstalling tensorboard-1.12.2:\n",
      "      Successfully uninstalled tensorboard-1.12.2\n",
      "Successfully installed tensorboard-1.15.0\n",
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.16.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (41.2.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: libsixel-python in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-hub\n",
    "!pip install Pillow\n",
    "!pip install nltk\n",
    "!pip install libsixel-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2025,
     "status": "ok",
     "timestamp": 1570613313320,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "-cUvJlIa2TFB",
    "outputId": "ae21eb99-c58b-4693-c8a1-3b01b8ae258b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbin\u001b[0m/      \u001b[01;34mdev\u001b[0m/   \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mopt\u001b[0m/   \u001b[01;34msbin\u001b[0m/   \u001b[01;34mtensorflow-2.0.0-rc2\u001b[0m/  \u001b[01;34mvar\u001b[0m/\n",
      "\u001b[01;34mboot\u001b[0m/     \u001b[01;34metc\u001b[0m/   \u001b[01;34mlib64\u001b[0m/  \u001b[01;34mproc\u001b[0m/  \u001b[01;34msrv\u001b[0m/    \u001b[30;42mtmp\u001b[0m/\n",
      "\u001b[01;34mcontent\u001b[0m/  \u001b[01;34mhome\u001b[0m/  \u001b[01;34mmedia\u001b[0m/  \u001b[01;34mroot\u001b[0m/  \u001b[01;34mswift\u001b[0m/  \u001b[01;34mtools\u001b[0m/\n",
      "\u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mlib\u001b[0m/   \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mrun\u001b[0m/   \u001b[01;34msys\u001b[0m/    \u001b[01;34musr\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13246,
     "status": "ok",
     "timestamp": 1570613348307,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "ZHguK6TyiwIQ",
    "outputId": "62d9ec51-cb7a-444b-d837-c7500e8f38e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu==1.12.2 in /usr/local/lib/python3.6/dist-packages (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.12.0)\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow-gpu==1.12.2)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.2) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.2) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.2) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.2) (2.8.0)\n",
      "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "Successfully installed tensorboard-1.12.2\n"
     ]
    }
   ],
   "source": [
    "# Downgrade to TensorFlow 1.12.2\n",
    "!pip install --upgrade tensorflow-gpu==1.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28203,
     "status": "ok",
     "timestamp": 1570613379707,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "z9EInOVBixlJ",
    "outputId": "20a0275c-908c-45ec-e0ff-e0b9e2169b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-09 09:29:13--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
      "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.162.216\n",
      "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.162.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?yt90LfqpAFsVlhZXi76V6JGRKKT4aO62a9LjqRlk_VQMYv4TcfS12E1pWr2zibJrszthx35FprpulMk9LPuyoPKSxMqrjryy0ryLxFwQA7HwHzm6g_pHzD_17YI81pDO3mqpGZqVZyxxwmCnbK04RIq8EC27aiDljk0iwR_GJ2PNaTfXpFVLmNDhGrQUEyMSu7qjJ5NQngWIoEmAq0pQ [following]\n",
      "--2019-10-09 09:29:14--  https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?yt90LfqpAFsVlhZXi76V6JGRKKT4aO62a9LjqRlk_VQMYv4TcfS12E1pWr2zibJrszthx35FprpulMk9LPuyoPKSxMqrjryy0ryLxFwQA7HwHzm6g_pHzD_17YI81pDO3mqpGZqVZyxxwmCnbK04RIq8EC27aiDljk0iwR_GJ2PNaTfXpFVLmNDhGrQUEyMSu7qjJ5NQngWIoEmAq0pQ\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1212738714 (1.1G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’\n",
      "\n",
      "cuda-repo-ubuntu160 100%[===================>]   1.13G   203MB/s    in 5.7s    \n",
      "\n",
      "2019-10-09 09:29:20 (204 MB/s) - ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’ saved [1212738714/1212738714]\n",
      "\n",
      "(Reading database ... 140498 files and directories currently installed.)\n",
      "Preparing to unpack cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb ...\n",
      "Unpacking cuda-repo-ubuntu1604-9-0-local (9.0.176-1) over (9.0.176-1) ...\n",
      "Setting up cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
      "OK\n",
      "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
      "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
      "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
      "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
      "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [973 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,293 kB]\n",
      "Fetched 2,518 kB in 3s (752 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cuda is already the newest version (9.0.176-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 145 not upgraded.\n",
      "bin boot content cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb datalab dev etc home lib lib32 lib64 media mnt opt proc root run sbin srv swift sys tensorflow-2.0.0-rc2 tmp tools usr var Cuda reinstall completed. Restart runtime now! bin boot content cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb datalab dev etc home lib lib32 lib64 media mnt opt proc root run sbin srv swift sys tensorflow-2.0.0-rc2 tmp tools usr var\n"
     ]
    }
   ],
   "source": [
    "#Install Cuda 9.0 \n",
    "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
    "!apt-get update\n",
    "!apt-get install cuda=9.0.176-1\n",
    "!echo ****** Cuda reinstall completed. Restart runtime now! *******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1570613383198,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "Bbx8q-gn3yv6",
    "outputId": "79ee1169-bb8a-4d0e-fd41-4a06d1624912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running TensorFlow version 1.12.2 on Colab!\n"
     ]
    }
   ],
   "source": [
    "#must be 1.12.2\n",
    "import tensorflow as tf\n",
    "print(\"Now running TensorFlow version %s on Colab!\" %tf.VERSION)\n",
    "assert tf.VERSION == '1.12.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2203,
     "status": "ok",
     "timestamp": 1570613386437,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "0uHaUuqckrtV",
    "outputId": "10258825-2c98-4b74-bb1e-62829d865cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:03_CDT_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n"
     ]
    }
   ],
   "source": [
    "#must be release 9 \n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1570613386439,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "WaiWK47j4MRB",
    "outputId": "6f35616b-b1e9-4d67-b930-254969d1da57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK downloader\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xu7hCQ_Clbi1"
   },
   "source": [
    "# **Load pretrained biggan model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2908,
     "status": "ok",
     "timestamp": 1570613390999,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "gozGFhvak3iA",
    "outputId": "0506a494-94f4-467d-e98e-7a3727d9eb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-pretrained-BigGAN'...\n",
      "remote: Enumerating objects: 65, done.\u001b[K\n",
      "remote: Counting objects:   1% (1/65)\u001b[K\r",
      "remote: Counting objects:   3% (2/65)\u001b[K\r",
      "remote: Counting objects:   4% (3/65)\u001b[K\r",
      "remote: Counting objects:   6% (4/65)\u001b[K\r",
      "remote: Counting objects:   7% (5/65)\u001b[K\r",
      "remote: Counting objects:   9% (6/65)\u001b[K\r",
      "remote: Counting objects:  10% (7/65)\u001b[K\r",
      "remote: Counting objects:  12% (8/65)\u001b[K\r",
      "remote: Counting objects:  13% (9/65)\u001b[K\r",
      "remote: Counting objects:  15% (10/65)\u001b[K\r",
      "remote: Counting objects:  16% (11/65)\u001b[K\r",
      "remote: Counting objects:  18% (12/65)\u001b[K\r",
      "remote: Counting objects:  20% (13/65)\u001b[K\r",
      "remote: Counting objects:  21% (14/65)\u001b[K\r",
      "remote: Counting objects:  23% (15/65)\u001b[K\r",
      "remote: Counting objects:  24% (16/65)\u001b[K\r",
      "remote: Counting objects:  26% (17/65)\u001b[K\r",
      "remote: Counting objects:  27% (18/65)\u001b[K\r",
      "remote: Counting objects:  29% (19/65)\u001b[K\r",
      "remote: Counting objects:  30% (20/65)\u001b[K\r",
      "remote: Counting objects:  32% (21/65)\u001b[K\r",
      "remote: Counting objects:  33% (22/65)\u001b[K\r",
      "remote: Counting objects:  35% (23/65)\u001b[K\r",
      "remote: Counting objects:  36% (24/65)\u001b[K\r",
      "remote: Counting objects:  38% (25/65)\u001b[K\r",
      "remote: Counting objects:  40% (26/65)\u001b[K\r",
      "remote: Counting objects:  41% (27/65)\u001b[K\r",
      "remote: Counting objects:  43% (28/65)\u001b[K\r",
      "remote: Counting objects:  44% (29/65)\u001b[K\r",
      "remote: Counting objects:  46% (30/65)\u001b[K\r",
      "remote: Counting objects:  47% (31/65)\u001b[K\r",
      "remote: Counting objects:  49% (32/65)\u001b[K\r",
      "remote: Counting objects:  50% (33/65)\u001b[K\r",
      "remote: Counting objects:  52% (34/65)\u001b[K\r",
      "remote: Counting objects:  53% (35/65)\u001b[K\r",
      "remote: Counting objects:  55% (36/65)\u001b[K\r",
      "remote: Counting objects:  56% (37/65)\u001b[K\r",
      "remote: Counting objects:  58% (38/65)\u001b[K\r",
      "remote: Counting objects:  60% (39/65)\u001b[K\r",
      "remote: Counting objects:  61% (40/65)\u001b[K\r",
      "remote: Counting objects:  63% (41/65)\u001b[K\r",
      "remote: Counting objects:  64% (42/65)\u001b[K\r",
      "remote: Counting objects:  66% (43/65)\u001b[K\r",
      "remote: Counting objects:  67% (44/65)\u001b[K\r",
      "remote: Counting objects:  69% (45/65)\u001b[K\r",
      "remote: Counting objects:  70% (46/65)\u001b[K\r",
      "remote: Counting objects:  72% (47/65)\u001b[K\r",
      "remote: Counting objects:  73% (48/65)\u001b[K\r",
      "remote: Counting objects:  75% (49/65)\u001b[K\r",
      "remote: Counting objects:  76% (50/65)\u001b[K\r",
      "remote: Counting objects:  78% (51/65)\u001b[K\r",
      "remote: Counting objects:  80% (52/65)\u001b[K\r",
      "remote: Counting objects:  81% (53/65)\u001b[K\r",
      "remote: Counting objects:  83% (54/65)\u001b[K\r",
      "remote: Counting objects:  84% (55/65)\u001b[K\r",
      "remote: Counting objects:  86% (56/65)\u001b[K\r",
      "remote: Counting objects:  87% (57/65)\u001b[K\r",
      "remote: Counting objects:  89% (58/65)\u001b[K\r",
      "remote: Counting objects:  90% (59/65)\u001b[K\r",
      "remote: Counting objects:  92% (60/65)\u001b[K\r",
      "remote: Counting objects:  93% (61/65)\u001b[K\r",
      "remote: Counting objects:  95% (62/65)\u001b[K\r",
      "remote: Counting objects:  96% (63/65)\u001b[K\r",
      "remote: Counting objects:  98% (64/65)\u001b[K\r",
      "remote: Counting objects: 100% (65/65)\u001b[K\r",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects:   2% (1/36)\u001b[K\r",
      "remote: Compressing objects:   5% (2/36)\u001b[K\r",
      "remote: Compressing objects:   8% (3/36)\u001b[K\r",
      "remote: Compressing objects:  11% (4/36)\u001b[K\r",
      "remote: Compressing objects:  13% (5/36)\u001b[K\r",
      "remote: Compressing objects:  16% (6/36)\u001b[K\r",
      "remote: Compressing objects:  19% (7/36)\u001b[K\r",
      "remote: Compressing objects:  22% (8/36)\u001b[K\r",
      "remote: Compressing objects:  25% (9/36)\u001b[K\r",
      "remote: Compressing objects:  27% (10/36)\u001b[K\r",
      "remote: Compressing objects:  30% (11/36)\u001b[K\r",
      "remote: Compressing objects:  33% (12/36)\u001b[K\r",
      "remote: Compressing objects:  36% (13/36)\u001b[K\r",
      "remote: Compressing objects:  38% (14/36)\u001b[K\r",
      "remote: Compressing objects:  41% (15/36)\u001b[K\r",
      "remote: Compressing objects:  44% (16/36)\u001b[K\r",
      "remote: Compressing objects:  47% (17/36)\u001b[K\r",
      "remote: Compressing objects:  50% (18/36)\u001b[K\r",
      "remote: Compressing objects:  52% (19/36)\u001b[K\r",
      "remote: Compressing objects:  55% (20/36)\u001b[K\r",
      "remote: Compressing objects:  58% (21/36)\u001b[K\r",
      "remote: Compressing objects:  61% (22/36)\u001b[K\r",
      "remote: Compressing objects:  63% (23/36)\u001b[K\r",
      "remote: Compressing objects:  66% (24/36)\u001b[K\r",
      "remote: Compressing objects:  69% (25/36)\u001b[K\r",
      "remote: Compressing objects:  72% (26/36)\u001b[K\r",
      "remote: Compressing objects:  75% (27/36)\u001b[K\r",
      "remote: Compressing objects:  77% (28/36)\u001b[K\r",
      "remote: Compressing objects:  80% (29/36)\u001b[K\r",
      "remote: Compressing objects:  83% (30/36)\u001b[K\r",
      "remote: Compressing objects:  86% (31/36)\u001b[K\r",
      "remote: Compressing objects:  88% (32/36)\u001b[K\r",
      "remote: Compressing objects:  91% (33/36)\u001b[K\r",
      "remote: Compressing objects:  94% (34/36)\u001b[K\r",
      "remote: Compressing objects:  97% (35/36)\u001b[K\r",
      "remote: Compressing objects: 100% (36/36)\u001b[K\r",
      "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
      "Unpacking objects:   1% (1/65)   \r",
      "Unpacking objects:   3% (2/65)   \r",
      "Unpacking objects:   4% (3/65)   \r",
      "Unpacking objects:   6% (4/65)   \r",
      "Unpacking objects:   7% (5/65)   \r",
      "Unpacking objects:   9% (6/65)   \r",
      "Unpacking objects:  10% (7/65)   \r",
      "Unpacking objects:  12% (8/65)   \r",
      "Unpacking objects:  13% (9/65)   \r",
      "Unpacking objects:  15% (10/65)   \r",
      "Unpacking objects:  16% (11/65)   \r",
      "Unpacking objects:  18% (12/65)   \r",
      "Unpacking objects:  20% (13/65)   \r",
      "Unpacking objects:  21% (14/65)   \r",
      "Unpacking objects:  23% (15/65)   \r",
      "Unpacking objects:  24% (16/65)   \r",
      "Unpacking objects:  26% (17/65)   \r",
      "Unpacking objects:  27% (18/65)   \r",
      "Unpacking objects:  29% (19/65)   \r",
      "Unpacking objects:  30% (20/65)   \r",
      "Unpacking objects:  32% (21/65)   \r",
      "Unpacking objects:  33% (22/65)   \r",
      "Unpacking objects:  35% (23/65)   \r",
      "Unpacking objects:  36% (24/65)   \r",
      "Unpacking objects:  38% (25/65)   \r",
      "Unpacking objects:  40% (26/65)   \r",
      "Unpacking objects:  41% (27/65)   \r",
      "Unpacking objects:  43% (28/65)   \r",
      "Unpacking objects:  44% (29/65)   \r",
      "Unpacking objects:  46% (30/65)   \r",
      "Unpacking objects:  47% (31/65)   \r",
      "Unpacking objects:  49% (32/65)   \r",
      "Unpacking objects:  50% (33/65)   \r",
      "remote: Total 65 (delta 29), reused 61 (delta 27), pack-reused 0\u001b[K\n",
      "Unpacking objects:  52% (34/65)   \r",
      "Unpacking objects:  53% (35/65)   \r",
      "Unpacking objects:  55% (36/65)   \r",
      "Unpacking objects:  56% (37/65)   \r",
      "Unpacking objects:  58% (38/65)   \r",
      "Unpacking objects:  60% (39/65)   \r",
      "Unpacking objects:  61% (40/65)   \r",
      "Unpacking objects:  63% (41/65)   \r",
      "Unpacking objects:  64% (42/65)   \r",
      "Unpacking objects:  66% (43/65)   \r",
      "Unpacking objects:  67% (44/65)   \r",
      "Unpacking objects:  69% (45/65)   \r",
      "Unpacking objects:  70% (46/65)   \r",
      "Unpacking objects:  72% (47/65)   \r",
      "Unpacking objects:  73% (48/65)   \r",
      "Unpacking objects:  75% (49/65)   \r",
      "Unpacking objects:  76% (50/65)   \r",
      "Unpacking objects:  78% (51/65)   \r",
      "Unpacking objects:  80% (52/65)   \r",
      "Unpacking objects:  81% (53/65)   \r",
      "Unpacking objects:  83% (54/65)   \r",
      "Unpacking objects:  84% (55/65)   \r",
      "Unpacking objects:  86% (56/65)   \r",
      "Unpacking objects:  87% (57/65)   \r",
      "Unpacking objects:  89% (58/65)   \r",
      "Unpacking objects:  90% (59/65)   \r",
      "Unpacking objects:  92% (60/65)   \r",
      "Unpacking objects:  93% (61/65)   \r",
      "Unpacking objects:  95% (62/65)   \r",
      "Unpacking objects:  96% (63/65)   \r",
      "Unpacking objects:  98% (64/65)   \r",
      "Unpacking objects: 100% (65/65)   \r",
      "Unpacking objects: 100% (65/65), done.\n"
     ]
    }
   ],
   "source": [
    "#continue from here on after refreshing \n",
    "!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git\n",
    "!cd pytorch-pretrained-BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1570613396760,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "IDgLeuWA2nog",
    "outputId": "4e18dd1a-4d3d-4d91-dc51-7ba88c718bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbin\u001b[0m/                                                \u001b[01;34mproc\u001b[0m/\n",
      "\u001b[01;34mboot\u001b[0m/                                               \u001b[01;34mpytorch-pretrained-BigGAN\u001b[0m/\n",
      "\u001b[01;34mcontent\u001b[0m/                                            \u001b[01;34mroot\u001b[0m/\n",
      "cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb  \u001b[01;34mrun\u001b[0m/\n",
      "\u001b[01;34mdatalab\u001b[0m/                                            \u001b[01;34msbin\u001b[0m/\n",
      "\u001b[01;34mdev\u001b[0m/                                                \u001b[01;34msrv\u001b[0m/\n",
      "\u001b[01;34metc\u001b[0m/                                                \u001b[01;34mswift\u001b[0m/\n",
      "\u001b[01;34mhome\u001b[0m/                                               \u001b[01;34msys\u001b[0m/\n",
      "\u001b[01;34mlib\u001b[0m/                                                \u001b[01;34mtensorflow-2.0.0-rc2\u001b[0m/\n",
      "\u001b[01;34mlib32\u001b[0m/                                              \u001b[30;42mtmp\u001b[0m/\n",
      "\u001b[01;34mlib64\u001b[0m/                                              \u001b[01;34mtools\u001b[0m/\n",
      "\u001b[01;34mmedia\u001b[0m/                                              \u001b[01;34musr\u001b[0m/\n",
      "\u001b[01;34mmnt\u001b[0m/                                                \u001b[01;34mvar\u001b[0m/\n",
      "\u001b[01;34mopt\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3467,
     "status": "ok",
     "timestamp": 1570613412067,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "GSQOgwwwloTj",
    "outputId": "9f6dc90b-4936-470c-b99b-30b398bb17d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-biggan in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-biggan) (1.9.243)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-biggan) (1.16.5)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-biggan) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-biggan) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-biggan) (2.21.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-biggan) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-biggan) (1.12.243)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-biggan) (0.2.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-biggan) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-biggan) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-biggan) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-biggan) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-biggan) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-biggan) (2.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.243->boto3->pytorch-pretrained-biggan) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-biggan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSdugIX53Cu0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Below all directly copied from https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_3xVmxbrCat"
   },
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klqMq3OEzRuk"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1886,
     "status": "ok",
     "timestamp": 1570613420768,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "MaFoDudzvydG",
    "outputId": "65284bd0-1853-4643-a64d-bff832b45e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapse time: 1.4020702838897705\n"
     ]
    }
   ],
   "source": [
    "# Prepare an input\n",
    "# truncation originally 0.4\n",
    "start = time.time()\n",
    "truncation = 0.4\n",
    "class_vector = (one_hot_from_names(['soap bubble'], batch_size=1) + one_hot_from_names(['coffee'], batch_size=1))/2\n",
    "#class_vector = one_hot_from_names(['volcano'], batch_size=1)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1)\n",
    "\n",
    "# All in tensors\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "noise_vector = noise_vectors.to(device)\n",
    "class_vector = class_vectors.to(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Generate an image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "output = output.cpu()\n",
    "\n",
    "# Save results as png images\n",
    "save_as_images(output)\n",
    "end = time.time()\n",
    "print('Elapse time:',(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1849,
     "status": "ok",
     "timestamp": 1570613427248,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "II3nmtcl2u_s",
    "outputId": "1e792233-2a83-42a6-d049-5c9cebc73f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbin\u001b[0m/                                                output_2.png\n",
      "\u001b[01;34mboot\u001b[0m/                                               output_3.png\n",
      "\u001b[01;34mcontent\u001b[0m/                                            \u001b[01;34mproc\u001b[0m/\n",
      "cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb  \u001b[01;34mpytorch-pretrained-BigGAN\u001b[0m/\n",
      "\u001b[01;34mdatalab\u001b[0m/                                            \u001b[01;34mroot\u001b[0m/\n",
      "\u001b[01;34mdev\u001b[0m/                                                \u001b[01;34mrun\u001b[0m/\n",
      "\u001b[01;34metc\u001b[0m/                                                \u001b[01;34msbin\u001b[0m/\n",
      "\u001b[01;34mhome\u001b[0m/                                               \u001b[01;34msrv\u001b[0m/\n",
      "\u001b[01;34mlib\u001b[0m/                                                \u001b[01;34mswift\u001b[0m/\n",
      "\u001b[01;34mlib32\u001b[0m/                                              \u001b[01;34msys\u001b[0m/\n",
      "\u001b[01;34mlib64\u001b[0m/                                              \u001b[01;34mtensorflow-2.0.0-rc2\u001b[0m/\n",
      "\u001b[01;34mmedia\u001b[0m/                                              \u001b[30;42mtmp\u001b[0m/\n",
      "\u001b[01;34mmnt\u001b[0m/                                                \u001b[01;34mtools\u001b[0m/\n",
      "\u001b[01;34mopt\u001b[0m/                                                \u001b[01;34musr\u001b[0m/\n",
      "output_0.png                                        \u001b[01;34mvar\u001b[0m/\n",
      "output_1.png\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1570613437498,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "lXaE5H1s2x2k",
    "outputId": "4eff44d2-75d6-418e-8b45-ef4c0042f4f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5BpC1iiwT8L"
   },
   "source": [
    "# NOG NIET NAAR GEKEKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzQxBysV3CvB"
   },
   "outputs": [],
   "source": [
    "# AT START OF PROGRAM (if necessary for tensorflow stuff)\n",
    "#tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705071,
     "status": "error",
     "timestamp": 1570463564654,
     "user": {
      "displayName": "Zaida Rivai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDB65qKiJdl-21NseE6fWsuK1fA457c_Bo5tw_1qhQ=s64",
      "userId": "10541282058038287432"
     },
     "user_tz": -120
    },
    "id": "gxXWpqKj3CvE",
    "outputId": "1ceedaed-e631-4fd3-e00b-d7625de8c15b"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d199eec1d53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mate with picture [1,2,3] \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# looping evolution process\n",
    "# output_0 = child/main parent, output_1-3 = mating parent options\n",
    "\n",
    "while True:\n",
    "    inp = 0\n",
    "    while not inp in [\"1\",\"2\",\"3\",\"s\"]:\n",
    "        inp = input(\"Mate with picture [1,2,3] \")\n",
    "    if inp == \"s\":\n",
    "        break\n",
    "\n",
    "    #child_vector = (class_vectors[0] + class_vectors[int(inp)])/2\n",
    "    print(class_vectors[0])\n",
    "    child_vector = (class_vectors[0] + class_vectors[int(inp)])/2\n",
    "    \n",
    "#     sess = tf.Session()\n",
    "#     with sess.as_default():\n",
    "#         numpy_array = child_vector.eval()\n",
    "#         print(numpy_array)\n",
    "    \n",
    "    print(child_vector)\n",
    "#     print(class_vectors)\n",
    "#     print(class_vectors[0])\n",
    "#     print(class_vectors[int(inp)])\n",
    "#     print(child_vector)\n",
    "    parent_vectors = one_hot_from_names(['cock','clock','woollen'], batch_size=3)\n",
    "    print(parent_vectors)\n",
    "    #class_vector = np.append(child_vector, parent_vectors, axis=0)\n",
    "    noise_vectors = truncated_noise_sample(truncation=truncation, batch_size=1)\n",
    "\n",
    "    # All in tensors\n",
    "    noise_vectors = torch.from_numpy(noise_vectors)\n",
    "    tensor_parents = torch.from_numpy(parent_vectors)\n",
    "    print(tensor_parents)\n",
    "    class_vector = torch.cat((child_vector, tensor_parents), dim=0)\n",
    "\n",
    "    # Generate an image\n",
    "    with torch.no_grad():\n",
    "        output = model(noise_vectors, class_vector, truncation)\n",
    "\n",
    "    # Save results as png images\n",
    "    save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32T_Je4V4YD2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BigGAN PyTorch run TEMP_working_CUDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
