# -*- coding: utf-8 -*-
"""Upload_20_11_loopinterpolate_K.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12lqx_G7PdtWR8NZRiiSYyLa5cHrBYPUL

# Pretrained BIGGAN pre-process
"""

# !pip install tensorflow
# !pip install tensorflow-hub
# !pip install Pillow
# !pip install nltk
# !pip install libsixel-python

# Downgrade to TensorFlow 1.12.2
# !pip install --upgrade tensorflow-gpu==1.12.2

#Install Cuda 9.0
# !wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb
# !dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb
# !apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub
# !apt-get update
# !apt-get install cuda=9.0.176-1
# !echo ****** Cuda reinstall completed. Restart runtime now! *******

#must be 1.12.2
import tensorflow as tf
print("Now running TensorFlow version %s on Colab!" %tf.VERSION)
assert tf.VERSION == '1.12.2'

#must be release 9
# !nvcc --version

#NLTK downloader
import nltk
nltk.download('wordnet')

"""# **Load pretrained biggan model**

# Mount Colab with drive
"""

#run this cell
#generates a code in new tab
#copy code
#enter code in balkje
#wait

from google.colab import drive
drive.mount('/content/gdrive')

#continue from here on after refreshing Runtime --> restart runtime
#!git clone https://github.com/huggingface/pytorch-pretrained-BigGAN.git
#!cd pytorch-pretrained-BigGAN

"""# Install pytorch pretrained biggan"""

# !pip install pytorch-pretrained-biggan

from PIL import Image
import numpy as np

# Below all directly copied from https://github.com/huggingface/pytorch-pretrained-BigGAN
import torch
from pytorch_pretrained_biggan import (BigGAN, one_hot_from_int, one_hot_from_names, truncated_noise_sample,
                                       save_as_images, display_in_terminal)

# Load pre-trained model tokenizer (vocabulary)
model = BigGAN.from_pretrained('biggan-deep-512')

import time
from google.colab import files
from IPython.display import Image

# !cd /content/gdrive/My\ Drive/Colab\ Notebooks/evo_art_project/pytorch-pretrained-BigGAN/pytorch_pretrained_biggan/
# !pwd
# !cd /content/gdrive/My\ Drive/Colab\ Notebooks/evo_art_project/
# ls

"""# Save Images"""

# coding: utf-8
""" BigGAN utilities to prepare truncated noise samples and convert/save/display output images.
    Also comprise ImageNet utilities to prepare one hot input vectors for ImageNet classes.
    We use Wordnet so you can just input a name in a string and automatically get a corresponding
    imagenet class if it exists (or a hypo/hypernym exists in imagenet).
"""
from __future__ import absolute_import, division, print_function, unicode_literals

import json
import logging
from io import BytesIO

import numpy as np
from scipy.stats import truncnorm

logger = logging.getLogger(__name__)

NUM_CLASSES = 1000


def truncated_noise_sample(batch_size=1, dim_z=128, truncation=1., seed=None):
    """ Create a truncated noise vector.
        Params:
            batch_size: batch size.
            dim_z: dimension of z
            truncation: truncation value to use
            seed: seed for the random generator
        Output:
            array of shape (batch_size, dim_z)
    """
    state = None if seed is None else np.random.RandomState(seed)
    values = truncnorm.rvs(-2, 2, size=(batch_size, dim_z), random_state=state).astype(np.float32)
    return truncation * values


def convert_to_images(obj):
    """ Convert an output tensor from BigGAN in a list of images.
        Params:
            obj: tensor or numpy array of shape (batch_size, channels, height, width)
        Output:
            list of Pillow Images of size (height, width)
    """
    try:
        import PIL
    except ImportError:
        raise ImportError("Please install Pillow to use images: pip install Pillow")

    if not isinstance(obj, np.ndarray):
        obj = obj.detach().numpy()

    obj = obj.transpose((0, 2, 3, 1))
    obj = np.clip(((obj + 1) / 2.0) * 256, 0, 255)

    img = []
    for i, out in enumerate(obj):
        out_array = np.asarray(np.uint8(out), dtype=np.uint8)
        img.append(PIL.Image.fromarray(out_array))
    return img


def save_as_images(obj, file_name='output', path='images/'):
    """ Convert and save an output tensor from BigGAN in a list of saved images.
        Params:
            obj: tensor or numpy array of shape (batch_size, channels, height, width)
            file_name: path and beggingin of filename to save.
                Images will be saved as `file_name_{image_number}.png`
    """
    import os
    import cv2
    from PIL import Image

    #img = [<PIL.Image.Image image mode=RGB size=512x512 at 0x7F4B8B238208>]
    img = convert_to_images(obj)
    path = path
    # enumerate(img) = img_names: <enumerate object at 0x7f4b8b138750>
    img_names = enumerate(img)
    # print("img_names: {}".format(img_names))


    for i, out in img_names:
        current_file_name = file_name + '_%d.png' % i
        #out.save('/images/'+current_file_name,'png')
        out.save('/content/gdrive/My Drive/Colab Notebooks/evo_art_project/pytorch-pretrained-BigGAN/pytorch_pretrained_biggan/'+path+current_file_name)
        # print("Image {} has been saved".format(current_file_name))

"""## VANAF HIER WERKEND VOOR WEBINTERFACE"""

print(torch.cuda.is_available())
device = 0

def maak_een_mooi_plaatje(parent1, parent):
    """
    Example parameters:

    parent1: ./static/Test_0.png
    parent2: ./static/Test_1.png
    """

    return { 'parent1': parent1, 'parent2': parent2 }

def interpolate(lin_noise_vector, lin_class_vector, glob_idx, num):
    for i in range(num):
        noise_vector = torch.from_numpy(lin_noise_vector[i])
        class_vector = torch.from_numpy(lin_class_vector[i])

        noise_vector = noise_vector.to(device)
        class_vector = class_vector.to(device)

        # Generate an image
        with torch.no_grad():
            output = model(noise_vector, class_vector, truncation)

        # If you have a GPU put back on CPU
        output = output.to('cpu')

        save_as_images(output, '{:0>4}'.format(str(glob_idx)), path='images/Interpolation/')
        glob_idx += 1
    return glob_idx

# frames per second
frames = 21
# length movie
sec = 1.5
# frames needed
interpol = int(21*1.5)

truncation = 0.4

model.to(device)

# create initial child and 3 parents class vectors
class_vectors = np.random.choice([0,1],p=[0.99,0.01], size=(1,1000)).astype('float32')
for i in range(3):
    class_vectors = np.append(class_vectors, np.random.choice([0,1],p=[0.99,0.01], size=(1,1000)).astype('float32'),axis=0)

# Prepare initial child and 3 parents noise vectors
noise_vectors = truncated_noise_sample(truncation=truncation, batch_size=4)
# noise_vectors = truncated_noise_sample(truncation=truncation, batch_size=1)

while True:
    # All in tensors
    class_vectors_ten = torch.from_numpy(class_vectors)
    noise_vectors_ten = torch.from_numpy(noise_vectors)

    # Put on cuda
    class_vectors_cud = class_vectors_ten.to(device)
    noise_vectors_cud = noise_vectors_ten.to(device)

    # Generate images
    with torch.no_grad():
        output = model(noise_vectors_cud, class_vectors_cud, truncation)

    # If you have a GPU put back on CPU
    output = output.cpu()

    # Save results as png images
    save_as_images(output, file_name='Image', path='images/Main4/')

    display(Image('./images/Main4/Image_0.png',width=200, height=200))
    display(Image('./images/Main4/Image_1.png',width=200, height=200))
    display(Image('./images/Main4/Image_2.png',width=200, height=200))
    display(Image('./images/Main4/Image_3.png',width=200, height=200))

    # create options recombinationa + lin vectors (class and noise)
    ###

    # prompt user choice mating partner
    inp = 0
    parent_id = ["1","2","3","s"]
    while not inp in parent_id:
        # interpolate per 3 images, adapted function interpolate (per frame?)
        ###
        ### all different folders?
        inp = input("Mate with picture [1,2,3] ")
    if inp == "s":
        break

    # continue interpolation for one track (per 3/4 images)

    recom_class_vector = ((class_vectors[0] + class_vectors[int(inp)])/2).astype('float32')
    recom_noise_vector = ((noise_vectors[0] + noise_vectors[int(inp)])/2).astype('float32')

    lin_class_vector = np.linspace([class_vectors[0]], recom_class_vector, num=interpol)
    lin_noise_vector = np.linspace([noise_vectors[0]], recom_noise_vector, num=interpol)

    interid = 0
    interid = interpolate(lin_noise_vector, lin_class_vector, interid, interpol)

    class_vectors[0] = recom_class_vector
    for i in range(1,4):
        class_vectors[i] = np.random.choice([0,1],p=[0.99,0.01], size=(1,1000)).astype('float32')

    noise_vectors[0] = recom_noise_vector
    noise_vectors = np.append([noise_vectors[0]], truncated_noise_sample(truncation=truncation, batch_size=3), axis=0)

# create video from images in folder
import cv2
import os

image_folder = 'images/Interpolation/'
video_name = 'video9.avi'

images = sorted([img for img in os.listdir(image_folder) if img.endswith(".png")])
frame = cv2.imread(os.path.join(image_folder, images[0]))
height, width, layers = frame.shape

video = cv2.VideoWriter(video_name, 0, 8, (width,height))

print(images)

for image in images:
    video.write(cv2.imread(os.path.join(image_folder, image)))

cv2.destroyAllWindows()
video.release()
